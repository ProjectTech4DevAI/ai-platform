name: RAG Benchmark

run-name: RAG Benchmark by ${{ github.actor }}

on:
  workflow_dispatch:

jobs:
  benchmark:
    runs-on: ubuntu-latest

    strategy:
      matrix:
        service: [assistants, responses]
        dataset: [kunji, sneha]
        count: [2]

    env:
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      LANGFUSE_PUBLIC_KEY: ${{ secrets.LANGFUSE_PUBLIC_KEY }}
      LANGFUSE_SECRET_KEY: ${{ secrets.LANGFUSE_SECRET_KEY }}
      LANGFUSE_HOST: ${{ secrets.LANGFUSE_HOST }}
      LOCAL_CREDENTIALS_CREATE_PAYLOAD: ${{ secrets.LOCAL_CREDENTIALS_CREATE_PAYLOAD }}
      LOCAL_CREDENTIALS_API_KEY: ${{ secrets.LOCAL_CREDENTIALS_API_KEY }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup .env
        run: |
          cp .env.example .env
          echo "OPENAI_API_KEY=${{ env.OPENAI_API_KEY }}" >> .env
          echo "LANGFUSE_PUBLIC_KEY=${{ env.LANGFUSE_PUBLIC_KEY }}" >> .env
          echo "LANGFUSE_SECRET_KEY=${{ env.LANGFUSE_SECRET_KEY }}" >> .env
          echo "LANGFUSE_HOST=${{ env.LANGFUSE_HOST }}" >> .env
          echo "LOCAL_CREDENTIALS_CREATE_PAYLOAD=${{ env.LOCAL_CREDENTIALS_CREATE_PAYLOAD }}" >> .env
          echo "LOCAL_CREDENTIALS_API_KEY=${{ env.LOCAL_CREDENTIALS_API_KEY }}" >> .env
          echo "SECRET_KEY=secret123" >> .env
          echo "FIRST_SUPERUSER_PASSWORD=secret123" >> .env

      - name: Run server
        run: docker compose up -d

      - name: Wait for server to be ready
        run: sleep 10

      - name: Run migrations
        run: docker compose exec backend uv run alembic upgrade head

      - name: Seed data
        run: docker compose exec backend uv run python -m app.seed_data.seed_data

      - name: Create local credentials
        run: |
          curl -X POST http://localhost:8000/api/v1/credentials -H "Content-Type: application/json" -H "X-API-KEY: ${{ env.LOCAL_CREDENTIALS_API_KEY }}" -d "${{ env.LOCAL_CREDENTIALS_CREATE_PAYLOAD }}"

      - name: Run benchmark
        id: benchmark
        run: |
          # Run benchmark
          docker compose exec backend uv run ai-cli bench ${{ matrix.service }} --dataset ${{ matrix.dataset }} --count ${{ matrix.count }}
          # Get the latest benchmark file
          LATEST_BENCH=$(ls -t bench_results_*.csv | head -n1)
          echo "benchmark_file=$LATEST_BENCH" >> $GITHUB_OUTPUT

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: bench-${{ matrix.service }}-${{ matrix.dataset }}-${{ matrix.count }}.csv
          path: ${{ steps.benchmark.outputs.benchmark_file }}

      - name: Add results to job summary
        run: |
          echo "## Benchmark Results for ${{ matrix.service }} - ${{ matrix.dataset }}" >> $GITHUB_STEP_SUMMARY
          echo "```csv" >> $GITHUB_STEP_SUMMARY
          cat ${{ steps.benchmark.outputs.benchmark_file }} >> $GITHUB_STEP_SUMMARY
          echo "```" >> $GITHUB_STEP_SUMMARY

      - name: Cleanup
        if: always()
        run: docker compose down
